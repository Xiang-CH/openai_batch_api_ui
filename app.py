import gradio as gr
import dotenv
import os
import re
import uuid
import pandas as pd
from openai import OpenAI
from batch_apis import to_batch_jsonl, start_batch_job, get_batch_results, format_batch_results

dotenv.load_dotenv()
os.chdir(os.path.dirname(__file__))

DEFAULT_MODEL = "gpt-4o"
DEFAULT_OUTPUT_COLUMN = "gpt_response"
DEFAULT_TEMPERATURE = 0.5
DEFAULT_TOP_P = 0.9

URL = "/v1/chat/completions"

if not os.path.exists("data"):
    os.mkdir("data")
    os.mkdir("data/metas")
    os.mkdir("data/output")

file_path = {
    "jsonl": "data/metas/",
    "output": "data/output/"
}

def save_api_key(api_key):
    dotenv.set_key(".env", "OPENAI_API_KEY", api_key)

def get_params_from_prompt(sys_prompt, user_prompt):
    prompt = sys_prompt + user_prompt
    keys = re.findall(r'\{(\w+)\}', prompt)
    if len(keys) == 0:
        return "æç¤ºè¯ä¸­æ²¡æœ‰å‚æ•°"
    return ", ".join(keys)

def get_params_from_prompt_list(prompt):
    keys = re.findall(r'\{(\w+)\}', prompt)
    return keys

def check_file(file):
    if file is None:
        gr.Warning("è¯·ä¸Šä¼ æ–‡ä»¶!", duration=5)
        return [None, None]
    if not (file.name.endswith(".csv") or file.name.endswith(".xlsx")):
        gr.Warning("æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼ csvæˆ–xlsxæ–‡ä»¶!", duration=5)
        return [None, None]
    df = pd.read_csv(file) if file.name.endswith(".csv") else pd.read_excel(file)
    return [file, gr.Dataframe(df, label="åŸå§‹æ•°æ®è¡¨", interactive=False, visible=True)]

def request_batch(api_key, model_name, temperature, top_p, frequency_penalty, presence_penalty, system_prompt, user_prompt, df, output_column):
    # return "temp.xlsx"
    if not model_name:
        model_name = DEFAULT_MODEL
    if not output_column:
        output_column = DEFAULT_OUTPUT_COLUMN

    if api_key is None:
        gr.Warning("è¯·å¡«å†™æ­£ç¡®çš„OpenAI API Key!", duration=5)
        return
    if df is None:
        gr.Warning("è¯·ä¸Šä¼ æ–‡ä»¶!", duration=5)
        return
    if system_prompt is None:
        gr.Warning("è¯·å¡«å†™ç³»ç»Ÿæç¤ºè¯(System Prompt)!", duration=5)
        return
    if user_prompt is None:
        gr.Warning("è¯·å¡«å†™ç”¨æˆ·æç¤ºè¯(User Prompt)!", duration=5)
        return

    if output_column in df.columns:
        gr.Warning(f"è¾“å‡ºå‚æ•°åâ€œ{output_column}â€å·²ç»åœ¨æ•°æ®è¡¨ä¸­è¯·æ£€æŸ¥!", duration=5)
        return

    prompt = system_prompt + user_prompt
    keys = get_params_from_prompt_list(prompt)
    params_exist = True
    for param in keys:
        if param not in df.columns:
            gr.Warning(f"å‚æ•°â€œ{param}â€ä¸åœ¨æ•°æ®è¡¨ä¸­è¯·æ£€æŸ¥!", duration=5)
            params_exist = False
    if not params_exist:
        return
    
    try:
        client = OpenAI(api_key=api_key)
        models = [m.id for m in client.models.list()]
        if model_name not in models:
            gr.Warning(f"æ¨¡å‹ {model_name} ä¸å­˜åœ¨!", duration=5)
            return
    except:
        gr.Error("OpenAI API Key é”™è¯¯æˆ–ç½‘ç»œç¯å¢ƒé”™è¯¯ï¼", duration=5)
        return
    
    options = {
        "temperature": temperature,
        "top_p": top_p,
        "frequency_penalty": frequency_penalty,
        "presence_penalty": presence_penalty
    }

    file_name = f"{uuid.uuid4()}"
    jsonl_request_file = file_path['jsonl'] + file_name + '_req.jsonl'
    if not to_batch_jsonl(df, jsonl_request_file, system_prompt, user_prompt, model_name, URL, options, json_mode=False):
        return gr.Error(f"å†™å…¥Jsonlæ–‡ä»¶å¤±è´¥")
    batch_id = start_batch_job(jsonl_request_file)
    if not batch_id:
        return
    jsonl_response_file = file_path['jsonl'] + file_name + '_res.jsonl'
    if not get_batch_results(batch_id, jsonl_response_file):
        return
    excel_file_out = file_path['output'] + file_name + '.xlsx'
    if format_batch_results(df, jsonl_response_file, excel_file_out, output_column):
        return excel_file_out
    return
    



with gr.Blocks() as demo:
    gr.Markdown("## OpenAI æ‰¹å¤„ç† UI")
    with gr.Row():
        api_key = gr.Textbox(label="OpenAI API Key", value=os.getenv("OPENAI_API_KEY"), placeholder="è¾“å…¥ä½ çš„OpenAI API Key")
        model_name = gr.Textbox(label="Model Name", placeholder=DEFAULT_MODEL)
        api_key.change(save_api_key, inputs=api_key)
    
    with gr.Row():
        temperature = gr.Slider(label="Temperature", minimum=0.0, maximum=1.0, step=0.1, value=DEFAULT_TEMPERATURE, interactive=True)
        top_p = gr.Slider(label="Top P", minimum=0.0, maximum=1.0, step=0.1, value=DEFAULT_TOP_P, interactive=True)
        frequency_penalty = gr.Slider(label="Frequency Penalty", minimum=0.0, maximum=1.0, step=0.1, value=0.0, interactive=True)
        presence_penalty = gr.Slider(label="Presence Penalty", minimum=0.0, maximum=1.0, step=0.1, value=0.0, interactive=True)

    with gr.Row():
        with gr.Column():
            system_prompt = gr.Textbox(label="System Prompt", placeholder="è¾“å…¥ç³»ç»Ÿæç¤ºè¯ï¼ˆç”¨{ }è¡¨ç¤ºå‚æ•°ï¼‰")
            user_prompt = gr.Textbox(label="User Prompt", placeholder="è¾“å…¥ç”¨æˆ·æç¤ºè¯ï¼ˆç”¨{ }è¡¨ç¤ºå‚æ•°ï¼‰", lines=5)
        with gr.Column():
            params = gr.Textbox(label="è¾“å…¥å‚æ•°", placeholder="åœ¨å·¦ä¾§è¾“å…¥æç¤ºè¯è‡ªåŠ¨è¯†åˆ«å‚æ•°å", interactive=False, lines=5)
            output_column = gr.Textbox(label="è¾“å‡ºå‚æ•°å", placeholder="gpt_response")
        user_prompt.change(fn=get_params_from_prompt, inputs=[system_prompt, user_prompt], outputs=params)
        system_prompt.change(fn=get_params_from_prompt, inputs=[system_prompt, user_prompt], outputs=params)

    file_in = gr.File(label="ä¸Šä¼ åŸå§‹æ•°æ®è¡¨")
    df = gr.Dataframe(label="åŸå§‹æ•°æ®è¡¨", interactive=False, visible=False)
    file_in.upload(check_file, inputs=file_in, outputs=[file_in, df])
    file_in.clear(lambda x: None, inputs=file_in, outputs=df)

    request_btn = gr.Button("è¯·æ±‚æ‰¹å¤„ç†ğŸš€")
    file_out = gr.File(label="ä¸‹è½½å¤„ç†åæ•°æ®è¡¨")
    request_btn.click(request_batch, inputs=[api_key, model_name, temperature, top_p, frequency_penalty, presence_penalty, system_prompt, user_prompt, df,output_column], outputs=file_out)

    # with gr.Row() as metas:
    #     batch_id = gr.Textbox(label="Batch ID", placeholder="è¯·æ±‚æ‰¹å¤„ç†ä»»åŠ¡åæ˜¾ç¤º", interactive=False)
    #     batch_id = gr.Textbox(label="Batch ID", placeholder="è¯·æ±‚æ‰¹å¤„ç†ä»»åŠ¡åæ˜¾ç¤º", interactive=False)

    

if __name__ == "__main__":
    dotenv.load_dotenv()
    client = OpenAI()
    demo.launch()